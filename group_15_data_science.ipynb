{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8QCVSIePgILq"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "UHEZueSIgRs6",
    "outputId": "3e999bc8-c542-49c7-ba1c-08a185b171aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Group 15 data science project\\nDATASET:\\n(https://www.kaggle.com/competitions/playground-series-s4e11/data)\\n\\nPROCESS:\\n1. Load and clean the data\\n2. EDA - Exploring data\\n3. Data Pre-processing\\n4. Creating model\\n5. Cross-validated training\\n6. Evaluation of model\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Group 15 data science project\n",
    "DATASET:\n",
    "(https://www.kaggle.com/competitions/playground-series-s4e11/data)\n",
    "\n",
    "PROCESS:\n",
    "1. Load and clean the data\n",
    "2. EDA - Exploring data\n",
    "3. Data Pre-processing\n",
    "4. Creating model\n",
    "5. Cross-validated training\n",
    "6. Evaluation of model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqqFvOoTgDu6",
    "outputId": "c6c8ae27-fce4-49ab-f1df-4979c5e94236"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Loading and cleaning data\n",
    "\"\"\"\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Removing target Column\n",
    "target = train_df.pop('Depression')\n",
    "\n",
    "cleaning_transformations = [\n",
    "    {'drop': ['id', 'Name', 'City']},\n",
    "    {'handle_na': []}\n",
    "]\n",
    "\n",
    "# Define Cleaner Class\n",
    "class Cleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This class will be used as part of the ML Pipeline for cleaning and handling data\n",
    "    \"\"\"\n",
    "    def __init__(self, transformations):\n",
    "        self.transformations = transformations\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        x_temp = x.copy()\n",
    "        \n",
    "        for transformation in self.transformations:\n",
    "            for transformation_type, column_names in transformation.items():\n",
    "                if transformation_type == 'handle_na':\n",
    "                    x_temp = self.deal_with_na_values(x_temp)\n",
    "                elif transformation_type == 'drop':\n",
    "                    x_temp = self.drop_unneeded_columns(x_temp, column_names)  \n",
    "                            \n",
    "        return x_temp\n",
    "    \n",
    "    @staticmethod\n",
    "    def deal_with_na_values(data, verbose=False):\n",
    "        data.fillna(0, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_unneeded_columns(data, column_names):\n",
    "        return data.drop(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoXvVqRahumr",
    "outputId": "b0d80c20-9f8d-497b-ac3c-74a4582cb86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Breakdown of Binary columns values []\n",
      "Unique values in column \"id\": [     0      1      2 ... 140697 140698 140699]\n",
      "Unique values in column \"Name\": ['Aaradhya' 'Vivan' 'Yuvraj' 'Rhea' 'Vani' 'Ritvik' 'Rajveer' 'Aishwarya'\n",
      " 'Simran' 'Utkarsh' 'Aahana' 'Tejas' 'Aadhya' 'Kiran' 'Aditi' 'Suhani'\n",
      " 'Jiya' 'Bhavesh' 'Armaan' 'Ishaani' 'Prachi' 'Pratyush' 'Abhinav'\n",
      " 'Siddhesh' 'Aditya' 'Aarav' 'Asha' 'Kashish' 'Prisha' 'Chhavi' 'Tanmay'\n",
      " 'Vihaan' 'Shiv' 'Anvi' 'Darsh' 'Samar' 'Raunak' 'Mahi' 'Shaurya' 'Vidya'\n",
      " 'Jai' 'Ayush' 'Ansh' 'Anand' 'Yashvi' 'Shrey' 'Ritika' 'Mihir' 'Isha'\n",
      " 'Arjun' 'Rohan' 'Pratham' 'Nirvaan' 'Ishaan' 'Aarya' 'Riya' 'Aariv'\n",
      " 'Raghavendra' 'Mahika' 'Abhishek' 'Harshil' 'Janvi' 'Kartikeya' 'Shivam'\n",
      " 'Advait' 'Reyansh' 'Saanvi' 'Ivaan' 'Pallavi' 'Sneha' 'Ayaan' 'Aakash'\n",
      " 'Raghav' 'Satyam' 'Aarush' 'Vibha' 'Rupal' 'Sanya' 'Mira' 'Rashi' 'Shlok'\n",
      " 'Harsha' 'Divya' 'Pranav' 'Hrithik' 'Tushar' 'Garima' 'Zoya' 'Kian'\n",
      " 'Navya' 'Lakshay' 'Kriti' 'Palak' 'Aryan' 'Parth' 'Ishan' 'Rupak'\n",
      " 'Atharv' 'Aarti' 'Anirudh' 'Kabir' 'Sanjeev' 'Sanket' 'Tara' 'Gagan'\n",
      " 'Anjali' 'Gaurav' 'Vikram' 'Yogesh' 'Ila' 'Rishi' 'Ayansh' 'Kolkata'\n",
      " 'Kavya' 'Aanchal' 'Vedant' 'Samaira' 'Harsh' 'Nikita' 'Charvi' 'Ishita'\n",
      " 'Ishwar' 'Kanika' 'Ritik' 'Rahil' 'Ira' 'Pari' 'Tanya' 'Yamini' 'Vidhi'\n",
      " 'Shreya' 'Neha' 'Esha' 'Damini' 'Manvi' 'Shivansh' 'Nikhil' 'Arya'\n",
      " 'Deepak' 'Shruti' 'Vrinda' 'Anushka' 'Sara' 'Zara' 'Gauri' 'Soham'\n",
      " 'Nandini' 'Siddharth' 'Rudransh' 'Manan' 'Dhruv' 'Tina' 'Pihu' 'Lavanya'\n",
      " 'Anika' 'Sai' 'Tanisha' 'Amit' 'Arav' 'Chirag' 'Krishna' 'Pooja' 'Eshita'\n",
      " 'Leela' 'Siddhi' 'Vanya' 'Trisha' 'Vivaan' 'Diya' 'Veda' 'Keshav' 'Kunal'\n",
      " 'Arnav' 'Barkha' 'Nalini' 'Golkut' 'Jasmine' 'Mithila' 'Rupa' 'Nisha'\n",
      " 'Saurav' 'Radhika' 'Jhanvi' 'Monika' 'Varun' 'Aan' 'Dev' 'Rajat' 'Naina'\n",
      " 'Nishant' 'Yash' 'Vaishnavi' 'Himani' 'Meera' 'Om' 'Anaya' 'Aniket'\n",
      " 'Tanvi' 'Mayank' 'Ishaesh' 'Srishti' 'Lata' 'Mukund' 'Ranveer' 'Khushi'\n",
      " 'Aarohi' 'Bhavna' 'Neil' 'Shivak' 'Apoorva' 'Kartik' 'Avni' 'Vaanya'\n",
      " 'Kush' 'Karishma' 'Shanaya' 'Virat' 'Rudra' 'A.Ed' 'Kiara' 'Krav' 'Ayhan'\n",
      " 'Nakul' 'Kalyan' 'Parvik' 'Vlaan' 'Harini' 'Mahak' 'Shivar' 'Abishma'\n",
      " 'Prvi' 'K. Kavya' 'Aieter' 'Aarsh' 'Aarvi' 'Kupa' 'Rudegrav' 'Parvi'\n",
      " 'Siddh' 'Rajankot' 'Ani' 'Rupil' 'Aarash' 'Taurav' 'Rani' 'Aanya' 'BE'\n",
      " 'Aavya' 'Raghavvi' 'Anarush' 'Aisha' 'Viv' 'Ronnie' '18' 'Rietal' 'R.Com'\n",
      " 'Anohi' 'Vivani' 'Ayash' 'Anil' 'Tarsh' 'Aiya' 'Patna' 'Tinmay' 'Rhesh'\n",
      " 'Shivna' 'Nikya' 'Arnar' 'Vakash' 'Jush' 'Randik' 'Siddir' 'Adachi'\n",
      " 'Anakash' 'Ayut' 'Pariv' 'Jhaan' 'Rai' 'Hreya' 'Shivivaam' 'Prishti'\n",
      " 'M.Com' 'Gavrachi' 'Rivaan' 'Haurav' 'Noreen' 'Anish' 'Shivan' 'Aniv'\n",
      " 'Aohi' 'Vashi' 'Aariket' 'Aarat' 'Vohi' 'Vavya' 'Hra' 'Ishaam' 'Anhil'\n",
      " 'Rieta' 'Zahra' 'Jathesh' 'Jhav' 'Anh' 'Vidvi' 'Raghavik' 'Mahir' 'Sansh'\n",
      " 'Shivvi' 'Prishant' 'Rupar' 'Eirini' 'Tanak' 'Researcher' 'Shaina' 'Aani'\n",
      " 'Plumber' 'Nanya' 'Manik' 'Nanchal' 'Ayoub' 'Aam' 'Airav' 'Zegmay'\n",
      " 'Aarsush' 'Vidra' 'Kani' 'Ishma' 'Naly' 'Jaish' 'Rajya' 'Chrinda' 'Tani'\n",
      " 'Harshand' 'Ranchal' 'Vita' 'Prandini' 'Mahav' 'Nhanini' 'Anupal' 'Manr'\n",
      " 'Eikram' 'Arsha' 'Kartika' 'Pradhya' 'Harshir' 'Shivlok' 'Shivwar'\n",
      " 'Abarav' 'Ayya' 'Rupai' 'Rudrithik' 'Varanasi' 'K.Pharm' 'UX/UI Designer'\n",
      " 'Ariti' 'Manjun' 'Arvik' 'Thane' 'Rupika' 'Aaransh' 'Ijra' 'Anar' 'Parha'\n",
      " 'Vidha' 'Prayat' 'Yurav' 'Srinagar' 'Aaranya' 'Rupadhya' 'Anishi'\n",
      " 'Aikash' 'Nhanvi' 'Jiram' 'Rudrey' 'Shashi' 'Anya' 'Eisha' 'Vhaani'\n",
      " 'Prilak' 'Aarani' 'Nya' 'Harshav' 'Ewesh' 'Aanket' 'Tohar' 'Ryouvik'\n",
      " 'Niya' 'Anjun' 'Rupat' 'Anahk' 'Shivsh' 'Niki' 'Nishita' 'Rohik' 'Prishi'\n",
      " 'Ishaansh' 'Virar' 'Sharth' 'M.Tech' 'Shir' 'Kike' 'Shivvaan' 'Aarla'\n",
      " 'Nishi' 'Aarand' 'Adiya' 'Ritak' 'Kashi' 'Krey' 'Prarav' 'Kartal'\n",
      " 'Anariv' 'Irit' 'Kanisha' 'Anisha' 'Harshaun' 'Rietvik' 'Vasai-Virar'\n",
      " 'Ishlok' 'Vika' 'Rika' 'Aarun']\n",
      "Unique values in column \"Gender\": ['Female' 'Male']\n",
      "Unique values in column \"Age\": [49. 26. 33. 22. 30. 59. 47. 38. 24. 42. 55. 51. 39. 29. 50. 23. 56. 45.\n",
      " 37. 46. 31. 19. 28. 25. 41. 60. 18. 36. 21. 58. 44. 43. 40. 35. 54. 27.\n",
      " 52. 48. 57. 53. 34. 20. 32.]\n",
      "Unique values in column \"City\": ['Ludhiana' 'Varanasi' 'Visakhapatnam' 'Mumbai' 'Kanpur' 'Ahmedabad'\n",
      " 'Thane' 'Nashik' 'Bangalore' 'Patna' 'Rajkot' 'Jaipur' 'Pune' 'Lucknow'\n",
      " 'Meerut' 'Agra' 'Surat' 'Faridabad' 'Hyderabad' 'Srinagar' 'Ghaziabad'\n",
      " 'Kolkata' 'Chennai' 'Kalyan' 'Nagpur' 'Vadodara' 'Vasai-Virar' 'Delhi'\n",
      " 'Bhopal' 'Indore' 'Ishanabad' 'Vidhi' 'Ayush' 'Gurgaon' 'Krishna'\n",
      " 'Aishwarya' 'Keshav' 'Harsha' 'Nalini' 'Aditya' 'Malyansh' 'Raghavendra'\n",
      " 'Saanvi' 'M.Tech' 'Bhavna' 'Less Delhi' 'Nandini' 'M.Com' 'Plata'\n",
      " 'Atharv' 'Pratyush' 'City' '3.0' 'Less than 5 Kalyan' 'MCA' 'Mira'\n",
      " 'Moreadhyay' 'Morena' 'Ishkarsh' 'Kashk' 'Mihir' 'Vidya' 'Tolkata' 'Anvi'\n",
      " 'Krinda' 'Ayansh' 'Shrey' 'Ivaan' 'Vaanya' 'Gaurav' 'Harsh' 'Reyansh'\n",
      " 'Kashish' 'Kibara' 'Vaishnavi' 'Chhavi' 'Parth' 'Mahi' 'Tushar' 'MSc'\n",
      " 'No' 'Rashi' 'ME' 'Molkata' 'Researcher' 'Kagan' 'Armaan' 'Ithal'\n",
      " 'Nalyan' 'Dhruv' 'Galesabad' 'Itheg' 'Aaradhya' 'Pooja' 'Khushi'\n",
      " 'Khaziabad' 'Jhanvi' 'Unirar']\n",
      "Unique values in column \"Working Professional or Student\": ['Working Professional' 'Student']\n",
      "Unique values in column \"Profession\": ['Chef' 'Teacher' nan 'Business Analyst' 'Finanancial Analyst' 'Chemist'\n",
      " 'Electrician' 'Software Engineer' 'Data Scientist' 'Plumber'\n",
      " 'Marketing Manager' 'Accountant' 'Entrepreneur' 'HR Manager'\n",
      " 'UX/UI Designer' 'Content Writer' 'Educational Consultant'\n",
      " 'Civil Engineer' 'Manager' 'Pharmacist' 'Financial Analyst' 'Architect'\n",
      " 'Mechanical Engineer' 'Customer Support' 'Consultant' 'Judge'\n",
      " 'Researcher' 'Pilot' 'Graphic Designer' 'Travel Consultant'\n",
      " 'Digital Marketer' 'Lawyer' 'Research Analyst' 'Sales Executive' 'Doctor'\n",
      " 'Unemployed' 'Investment Banker' 'Family Consultant' 'B.Com' 'BE'\n",
      " 'Student' 'Yogesh' 'Dev' 'MBA' 'LLM' 'BCA' 'Academic' 'Profession'\n",
      " 'FamilyVirar' 'City Manager' 'BBA' 'Medical Doctor'\n",
      " 'Working Professional' 'MBBS' 'Patna' 'Unveil' 'B.Ed' 'Nagpur' 'Moderate'\n",
      " 'M.Ed' 'Analyst' 'Pranav' 'Visakhapatnam' 'PhD' 'Yuvraj']\n",
      "Unique values in column \"Academic Pressure\": [nan  5.  2.  3.  4.  1.]\n",
      "Unique values in column \"Work Pressure\": [ 5.  4. nan  1.  2.  3.]\n",
      "Unique values in column \"CGPA\": [    nan  8.97    5.9     7.03    5.59    8.13    5.7     9.54    8.04\n",
      "  9.79    8.38    6.1     7.04    8.52    5.64    8.58    6.51    7.25\n",
      "  7.83    9.93    8.74    6.73    5.57    8.59    7.1     6.08    5.74\n",
      "  9.86    6.7     6.21    5.87    6.37    9.72    5.88    9.56    6.99\n",
      "  5.24    9.21    7.85    6.95    5.86    7.92    9.66    8.94    9.71\n",
      "  7.87    5.6     7.9     5.46    6.79    8.7     7.38    8.5     7.09\n",
      "  9.82    8.89    7.94    9.11    6.75    7.53    9.49    9.01    7.64\n",
      "  5.27    6.      9.44    5.75    7.51    9.05    6.38    8.95    9.88\n",
      "  5.32    6.27    7.7     8.1     9.59    8.96    5.51    7.43    8.79\n",
      "  9.95    5.37    6.86    8.32    9.74    5.66    7.48    8.23    8.81\n",
      "  6.03    5.56    5.68    5.14    7.61    6.17    8.17    9.87    8.75\n",
      "  6.16    9.5     7.99    5.67    8.92    6.19    5.76    6.25    5.11\n",
      "  5.58    5.65    9.89    8.03    6.61    9.41    8.64    7.21    8.28\n",
      "  6.04    9.13    8.08    9.96    5.12    8.35    7.07    9.6     9.24\n",
      "  8.54    8.78    8.93    8.91    9.04    6.83    5.85    7.74    6.41\n",
      "  8.9     7.75    7.88    5.42    7.52    7.68    8.4     9.39    6.84\n",
      "  5.99    8.62    8.53    7.47    6.78    6.42    9.92    8.39    5.89\n",
      "  7.22    6.81    9.02    9.97    9.63    9.67    5.41    7.27    6.05\n",
      "  6.85    9.33    5.81    6.53    5.98    6.02    6.74    5.26    7.72\n",
      "  7.39    8.43    9.34    5.44    5.82    5.72    8.19    8.44    8.98\n",
      "  9.37    5.8     7.28    7.6     7.91    9.17    7.46    9.43    9.91\n",
      "  9.36    5.16    7.08    9.26    8.83   10.      7.8     9.46    6.63\n",
      "  7.24    6.47    7.77    5.06    7.17    8.24    6.88    9.03    5.08\n",
      "  5.45    8.46    9.19    6.36    8.73    7.11    9.12    9.4     8.11\n",
      "  9.98    5.55    8.61    8.14    6.89    9.84    5.48    8.21    7.82\n",
      "  8.55    5.79    8.77    8.29    6.92    7.37    9.7     6.26    7.26\n",
      "  7.5     6.82    7.15    5.77    5.91    5.1     7.71    9.06    5.71\n",
      "  5.84    9.42    6.23    6.29    5.25    9.69    9.9     6.39    8.09\n",
      "  5.83    5.47    6.56    8.71    9.94    6.69    5.52    7.3     7.02\n",
      "  6.33    8.07    8.37    8.      7.79    8.65    6.28    7.35    8.69\n",
      "  7.12    7.32    7.13    5.97    5.09    6.91    6.76    6.52    7.45\n",
      "  8.56    6.5     8.63    8.27    8.49    6.59    9.29    5.3     7.06\n",
      "  5.38    6.65    9.16    8.01    8.25    8.02    8.47    7.34    8.88\n",
      "  7.14    8.42    5.17    9.1     7.49    9.85    7.42    9.31    6.35\n",
      "  7.      5.39    5.61    9.78    9.25    5.69    9.47    8.16    7.23\n",
      "  6.46    8.26    6.32    6.77    8.85    5.03    7.65    5.78    6.24\n",
      "  5.35    6.06    7.78    6.64    7.0625  6.98    6.44    6.09  ]\n",
      "Unique values in column \"Study Satisfaction\": [nan  2.  5.  3.  4.  1.]\n",
      "Unique values in column \"Job Satisfaction\": [ 2.  3. nan  1.  5.  4.]\n",
      "Unique values in column \"Sleep Duration\": ['More than 8 hours' 'Less than 5 hours' '5-6 hours' '7-8 hours'\n",
      " 'Sleep_Duration' '1-2 hours' '6-8 hours' '4-6 hours' '6-7 hours'\n",
      " '10-11 hours' '8-9 hours' '40-45 hours' '9-11 hours' '2-3 hours'\n",
      " '3-4 hours' 'Moderate' '55-66 hours' '4-5 hours' '9-6 hours' '1-3 hours'\n",
      " 'Indore' '45' '1-6 hours' '35-36 hours' '8 hours' 'No' '10-6 hours'\n",
      " 'than 5 hours' '49 hours' 'Unhealthy' 'Work_Study_Hours' '3-6 hours'\n",
      " '45-48 hours' '9-5' 'Pune' '9-5 hours']\n",
      "Unique values in column \"Dietary Habits\": ['Healthy' 'Unhealthy' 'Moderate' 'Yes' 'Pratham' 'BSc' 'Gender' '3'\n",
      " 'More Healthy' 'Less than Healthy' 'Mihir' '1.0' 'Hormonal' 'Electrician'\n",
      " nan 'No Healthy' 'Less Healthy' 'M.Tech' 'Vegas' 'No' 'Male' 'Indoor'\n",
      " 'Class 12' '2']\n",
      "Unique values in column \"Degree\": ['BHM' 'LLB' 'B.Pharm' 'BBA' 'MCA' 'MD' 'BSc' 'ME' 'B.Arch' 'BCA' 'BE'\n",
      " 'MA' 'B.Ed' 'B.Com' 'MBA' 'M.Com' 'MHM' 'BA' 'Class 12' 'M.Tech' 'PhD'\n",
      " 'M.Ed' 'MSc' 'B.Tech' 'LLM' 'MBBS' 'M.Pharm' 'UX/UI Designer' 'MPA' 'BH'\n",
      " 'Nalini' 'BEd' 'B.Sc' 'Veda' 'Bhopal' 'S.Tech' 'Degree' '20' 'Class 11'\n",
      " 'H_Pharm' 'M' 'P.Com' 'BPharm' 'Business Analyst' 'M.Arch' 'LL.Com'\n",
      " 'Data Scientist' 'MPharm' 'L.Ed' 'P.Pharm' 'Kalyan' 'Unite' 'BArch'\n",
      " 'HR Manager' 'Badhya' 'S.Pharm' 'LLBA' 'Vrinda' 'M. Business Analyst'\n",
      " 'Bhavesh' '0' 'LLCom' '29' 'MTech' 'Vivaan' 'BPA' 'Plumber' '5.61' 'Brit'\n",
      " 'B.03' 'Ritik' '5.56' 'MEd' 'B' 'B BA' '7.06' 'B.B.Arch' 'ACA' 'Brithika'\n",
      " 'CGPA' '24' 'M_Tech' 'Pihu' 'BB' 'Jhanvi' 'LLTech' 'Aarav' 'Entrepreneur'\n",
      " '8.56' 'LHM' 'Lata' 'S.Arch' 'Marsh' 'HCA' '5.88' 'B.Student' 'LL B.Ed'\n",
      " 'M.S' 'Navya' 'Mahika' nan 'K.Ed' 'B.3.79' 'Mthanya'\n",
      " 'Working Professional' 'Esha' 'LLS' 'LLEd' 'E.Tech' 'Doctor' 'N.Pharm'\n",
      " 'LCA' 'B B.Com' 'RCA' 'Mihir' 'Advait']\n",
      "Unique values in column \"Have you ever had suicidal thoughts ?\": ['No' 'Yes']\n",
      "Unique values in column \"Work/Study Hours\": [ 1.  7.  3. 10.  9.  6.  8.  2.  0.  5. 12.  4. 11.]\n",
      "Unique values in column \"Financial Stress\": [ 2.  3.  1.  4.  5. nan]\n",
      "Unique values in column \"Family History of Mental Illness\": ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. EDA - This is the class that will allow us to display information about the data\n",
    "         The idea is that this information that we can extract/plot will allow us to tweak out data-preprocessing pipeline \n",
    "         to achieve better and more generalisable results\n",
    "\"\"\"\n",
    "\n",
    "class DataAnalyser:\n",
    "    \n",
    "    def __init__(self, base_train_df):\n",
    "        self.base_train_df = base_train_df\n",
    "        \n",
    "    def view_basic_analysis(self):\n",
    "        self.view_unique_columns()\n",
    "        \n",
    "    def view_unique_columns(self):\n",
    "        print('[] Breakdown of Binary columns values []')\n",
    "        for column in self.base_train_df.columns:\n",
    "            print(f'Unique values in column \"{column}\": {self.base_train_df[column].unique()}')\n",
    "                \n",
    "analyser = DataAnalyser(train_df)\n",
    "analyser.view_basic_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "cbcCgqZwhwLj",
    "outputId": "3eb24c4c-30c3-498c-c900-a000d3540fd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender       Age  Working Professional or Student  Academic Pressure  \\\n",
      "0       1  0.738095                                0                0.0   \n",
      "1       0  0.190476                                0                0.0   \n",
      "2       0  0.357143                                1                1.0   \n",
      "3       0  0.095238                                0                0.0   \n",
      "4       1  0.285714                                0                0.0   \n",
      "\n",
      "   Work Pressure   CGPA  Study Satisfaction  Job Satisfaction  Sleep Duration  \\\n",
      "0            1.0  0.000                 0.0               0.4             9.0   \n",
      "1            0.8  0.000                 0.0               0.6             4.0   \n",
      "2            0.0  0.897                 0.4               0.0             5.5   \n",
      "3            1.0  0.000                 0.0               0.2             4.0   \n",
      "4            0.2  0.000                 0.0               0.2             5.5   \n",
      "\n",
      "   Dietary Habits  ...  Degree_Ritik  Degree_S.Arch  Degree_S.Pharm  \\\n",
      "0             1.0  ...         False          False           False   \n",
      "1             4.0  ...         False          False           False   \n",
      "2             1.0  ...         False          False           False   \n",
      "3             3.0  ...         False          False           False   \n",
      "4             4.0  ...         False          False           False   \n",
      "\n",
      "   Degree_S.Tech  Degree_UX/UI Designer  Degree_Unite  Degree_Veda  \\\n",
      "0          False                  False         False        False   \n",
      "1          False                  False         False        False   \n",
      "2          False                  False         False        False   \n",
      "3          False                  False         False        False   \n",
      "4          False                  False         False        False   \n",
      "\n",
      "   Degree_Vivaan  Degree_Vrinda  Degree_Working Professional  \n",
      "0          False          False                        False  \n",
      "1          False          False                        False  \n",
      "2          False          False                        False  \n",
      "3          False          False                        False  \n",
      "4          False          False                        False  \n",
      "\n",
      "[5 rows x 195 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Data Pre-Processing\n",
    "\n",
    "COLUMNS -\n",
    "id: Can be dropped\n",
    "Name: Can be dropped\n",
    "Gender: binary encoding\n",
    "age: Temporarily okay but will need normalised\n",
    "city: Can be dropped\n",
    "Working professional or Student: Binary encoding\n",
    "Profession: One-hot-encoding (TEMPORARILY DROPPED)\n",
    "Academic Pressure: Temporarily okay but will need normalised\n",
    "Work Pressure: Temporarily okay but will need normalised\n",
    "CGPA: replace NaN with 0 - also will need normalised\n",
    "Study Satisfaction: replace NaN with 0 - also will need normalised\n",
    "Job Satisfaction: replace NaN with 0 - also will need normalised\n",
    "Sleep Duration: Ordinal Encoding (TEMPORARILY DROPPED)\n",
    "Dietary Habits: Ordinal Encoding (TEMPORARILY DROPPED)\n",
    "Degree: One-hot-encoding (TEMPORARILY DROPPED)\n",
    "Suicidal Thoughts: Binary Encoding\n",
    "Work/Study Hours: Normalised\n",
    "Financial stress: Normalised\n",
    "Mental Illness: Binary Encoding\n",
    "Depression: Target variable (no pre-processing needed)\n",
    "\"\"\"\n",
    "\n",
    "preprocessing_transformations = [\n",
    "    {'binary_encode': ['Gender', 'Have you ever had suicidal thoughts ?',\n",
    "                       'Family History of Mental Illness',\n",
    "                       'Working Professional or Student']},\n",
    "    {'map_sleep_column': ['Sleep Duration']},\n",
    "    {'map_diet_column': ['Dietary Habits']},\n",
    "    {'frequency_encode': ['Profession', 'Degree']},\n",
    "    {'normalise': ['Financial Stress', 'Age', 'Academic Pressure', 'Work Pressure',\n",
    "                   'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']}\n",
    "]\n",
    "\n",
    "\n",
    "class PreProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This class will handle the Pre-Processin of our data before passing to the Model\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, transformations):\n",
    "        self.transformations = transformations\n",
    "        self.mappings = {\n",
    "            'Gender': {'Male': 0, 'Female': 1},\n",
    "            'Have you ever had suicidal thoughts ?': {'Yes': 0, 'No': 1},\n",
    "            'Family History of Mental Illness': {'Yes': 0, 'No': 1},\n",
    "            'Working Professional or Student': {'Working Professional': 0, 'Student': 1},\n",
    "        }\n",
    "        self.sleep_mapping = {\n",
    "        \"More than 8 hours\":9,\n",
    "        'Less than 5 hours':4,\n",
    "        '5-6 hours':5.5,\n",
    "        '7-8 hours':7.5,\n",
    "        '1-2 hours':1.5,\n",
    "        '6-8 hours':7,\n",
    "        '4-6 hours':5,\n",
    "        '6-7 hours':6.5,\n",
    "        '10-11 hours':10.5,\n",
    "        '8-9 hours':8.5,\n",
    "        '9-11 hours':10,\n",
    "        '2-3 hours':2.5,\n",
    "        '3-4 hours':3.5,\n",
    "        'Moderate':6,\n",
    "        '4-5 hours':4.5,\n",
    "        '9-6 hours':7.5,\n",
    "        '1-3 hours':2,\n",
    "        '1-6 hours':4,\n",
    "        '8 hours':8,\n",
    "        '10-6 hours':8,\n",
    "        'Unhealthy':3,\n",
    "        'Work_Study_Hours':6,\n",
    "        '3-6 hours':4.5,\n",
    "        '9-5':7,\n",
    "        '9-5 hours':7,\n",
    "        }\n",
    "        self.diet_mapping ={\n",
    "            'More Healty':0,\n",
    "            'Healthy':1,\n",
    "            'Less than Healthy':2,\n",
    "            'Less Healthy':2,\n",
    "            'Moderate':3,\n",
    "            'Unhealthy':4,   \n",
    "            'No Healthy':4,\n",
    "        }\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_temp = x.copy()        \n",
    "        \n",
    "        for transformation in self.transformations:\n",
    "            for transformation_name, column_names in transformation.items():\n",
    "                if transformation_name == 'drop_columns':\n",
    "                    x_temp = self.drop_columns(x_temp, column_names)\n",
    "                elif transformation_name == 'binary_encode':\n",
    "                    x_temp = self.encode_columns(x_temp, column_names, self.mappings)\n",
    "                elif transformation_name == 'normalise':\n",
    "                    x_temp = self.normalise_columns(x_temp, column_names) \n",
    "                elif transformation_name == 'map_sleep_column':\n",
    "                    x_temp = self.map_sleep_values(x_temp, column_names, self.sleep_mapping)\n",
    "                elif transformation_name == 'frequency_encode':\n",
    "                    x_temp = self.frequency_encode(x_temp, column_names)\n",
    "                elif transformation_name == 'map_diet_column':\n",
    "                    x_temp = self.map_dietary_value(x_temp, column_names, self.diet_mapping)\n",
    "                    \n",
    "        return x_temp\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_columns(data, column_names):\n",
    "        data.drop(columns=column_names, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_columns(data, column_names, mappings):\n",
    "        for column in column_names:\n",
    "            if column in mappings:\n",
    "                data[column] = data[column].map(mappings[column])\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def map_sleep_values(data, column_names, mapping):\n",
    "        for column in column_names:\n",
    "            data[column] = data[column].map(mapping)\n",
    "            data[column].fillna(data[column].mode()[0], inplace=True)  # Fill NaNs with the most frequent value\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def map_dietary_value(data, column_names, mapping):\n",
    "        for column in column_names:\n",
    "            data[column] = data[column].map(mapping)\n",
    "            data[column].fillna(data[column].mode()[0], inplace=True)  # Fill NaNs with the most frequent value\n",
    "        return data\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def frequency_encode(data, column_names):\n",
    "        for column in column_names:\n",
    "            if column in data.columns:\n",
    "                freq = data[column].value_counts() / len(data)\n",
    "                data[column] = data[column].map(freq)\n",
    "        return data\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def one_hot_encode(data, column_names):\n",
    "#         for column in column_names:\n",
    "#             if column in data.columns:\n",
    "#                 # Perform one-hot encoding using pd.get_dummies\n",
    "#                 one_hot = pd.get_dummies(data[column], prefix=column)\n",
    "#                 # Concatenate the one-hot encoded columns to the original data\n",
    "#                 data = pd.concat([data, one_hot], axis=1)\n",
    "#                 # Drop the original column after encoding\n",
    "#                 data.drop(columns=[column], inplace=True)\n",
    "#         return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalise_columns(data, column_names):\n",
    "        scaler = MinMaxScaler()  # Initialize MinMaxScaler\n",
    "        for column in column_names:\n",
    "            if column in data.columns:\n",
    "                # Reshape for MinMaxScaler since it expects 2D input\n",
    "                data[column] = scaler.fit_transform(data[[column]])\n",
    "        return data\n",
    "    \n",
    "data_pipeline = Pipeline([\n",
    "     ('cleaning', Cleaner(cleaning_transformations)),\n",
    "     ('preprocessing', PreProcessor(preprocessing_transformations))\n",
    "])\n",
    "\n",
    "# Apply the transformations to the data\n",
    "processed_data = data_pipeline.transform(train_df)\n",
    "\n",
    "# View the processed data\n",
    "print(processed_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Analysing results\n",
    "'''\n",
    "\n",
    "class ResultsAnalyser:\n",
    "    \n",
    "    def __init__(self, results):\n",
    "        self.results = results\n",
    "        self.process_results()\n",
    "        \n",
    "    def process_results(self):\n",
    "        # for results_set in self.results:\n",
    "            # ...put through function to build confusin matrix - \n",
    "        ...\n",
    "        \n",
    "    def view_results(self):\n",
    "        for result in self.results:\n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "sQ-OrqqibQNg",
    "outputId": "bf2de335-8ff8-40e3-f7fe-0035d1e09d56"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Degree_29\n- Degree_5.56\n- Degree_5.61\n- Degree_5.88\n- Degree_B.03\n- ...\nFeature names seen at fit time, yet now missing:\n- Degree_20\n- Degree_24\n- Degree_7.06\n- Degree_8.56\n- Degree_ACA\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[0;32m     51\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:508\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Degree_29\n- Degree_5.56\n- Degree_5.61\n- Degree_5.88\n- Degree_B.03\n- ...\nFeature names seen at fit time, yet now missing:\n- Degree_20\n- Degree_24\n- Degree_7.06\n- Degree_8.56\n- Degree_ACA\n- ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Creating Model / Training / Evaluating\n",
    "\"\"\"\n",
    "\n",
    "# Define model parameters\n",
    "logistic_regression_params = {'max_iter': 1000, 'random_state': 42}\n",
    "decision_tree_params = {'criterion': 'gini', 'max_depth': 3, 'random_state': 42}\n",
    "random_forest_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    "svm_params = {'kernel': 'linear', 'C': 1.0}\n",
    "knn_params = {'n_neighbors': 5}\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = []\n",
    "models.append({'Logistic_regression': LogisticRegression(**logistic_regression_params)})\n",
    "models.append({'decision_tree': DecisionTreeClassifier(**decision_tree_params)})\n",
    "models.append({'Random Forest': RandomForestClassifier(**random_forest_params)})\n",
    "# models.append({'SVM': SVC(**svm_params)})\n",
    "# models.append({'K-Nearest Neighbors': KNeighborsClassifier(**knn_params)})\n",
    "\n",
    "model_results = []\n",
    "for model_info in models:\n",
    "    for model_name, model in model_info.items():\n",
    "      # Define stratified k-fold cross-validation\n",
    "      n_splits = 5\n",
    "      skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "      # For tracking scores\n",
    "      fold = 1\n",
    "      accuracies = []\n",
    "\n",
    "      # Cross-validation loop\n",
    "      for train_index, val_index in skf.split(train_df, target):\n",
    "          # Split data\n",
    "          X_train, X_val = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "          y_train, y_val = target.iloc[train_index], target.iloc[val_index]\n",
    "        \n",
    "          # Define ML Pipeline\n",
    "          pipeline = Pipeline([\n",
    "              ('cleaning', Cleaner(cleaning_transformations)),\n",
    "              ('preprocessing', PreProcessor(preprocessing_transformations)),\n",
    "              ('classifier', model)\n",
    "          ])\n",
    "            \n",
    "          pipeline.fit(X_train, y_train)\n",
    "\n",
    "          # Predict on validation set\n",
    "          y_pred = pipeline.predict(X_val)\n",
    "\n",
    "          # Evaluate accuracy\n",
    "          acc = accuracy_score(y_val, y_pred)\n",
    "          accuracies.append(acc)\n",
    "            \n",
    "          print(f'Fold {fold}/5 for model: {model_name}')\n",
    "\n",
    "          fold += 1\n",
    "        \n",
    "      print({model_name: np.mean(accuracies)})\n",
    "\n",
    "      model_results.append({model_name: np.mean(accuracies)})\n",
    "        \n",
    "results_analyser = ResultsAnalyser(model_results)\n",
    "results_analyser.view_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqX9+9QcF2OWVdm77NBW4g",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
