{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "8QCVSIePgILq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "UHEZueSIgRs6",
        "outputId": "9a80006f-55e8-495b-9d5b-f8bfe3d10588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Group 15 data science project\\nDATASET:\\n(https://www.kaggle.com/competitions/playground-series-s4e11/data)\\n\\nPROCESS:\\n1. Load and clean the data\\n2. EDA - Exploring data\\n3. Data Pre-processing\\n4. Creating model\\n5. Cross-validated training\\n6. Evaluation of model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "\"\"\"Group 15 data science project\n",
        "DATASET:\n",
        "(https://www.kaggle.com/competitions/playground-series-s4e11/data)\n",
        "\n",
        "PROCESS:\n",
        "1. Load and clean the data\n",
        "2. EDA - Exploring data\n",
        "3. Data Pre-processing\n",
        "4. Creating model\n",
        "5. Cross-validated training\n",
        "6. Evaluation of model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "eqqFvOoTgDu6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1. Loading and cleaning data\n",
        "\n",
        "TODO:\n",
        "We need a better way of handling NA values in certain columns - KNN encoding?\n",
        "Run the DataAnalyser object before preprocessing (if verbose=True) such that it\n",
        "can present information about the data before we start altering it\n",
        "\"\"\"\n",
        "cleaning_transformations = [\n",
        "    {'drop': ['id', 'Name', 'City']},\n",
        "    {'handle_na': []}\n",
        "]\n",
        "\n",
        "# Define Cleaner Class\n",
        "class Cleaner(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    This class will be used as part of the ML Pipeline for cleaning and handling data\n",
        "    \"\"\"\n",
        "    def __init__(self, transformations):\n",
        "        self.transformations = transformations\n",
        "        self.data_analyser = DataAnalyser()\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "      self.data_analyser.view_cleaning_analysis(x, y)\n",
        "      return self\n",
        "\n",
        "    def transform(self, x):\n",
        "        x_temp = x.copy()\n",
        "\n",
        "        for transformation in self.transformations:\n",
        "            for transformation_type, column_names in transformation.items():\n",
        "                if transformation_type == 'handle_na':\n",
        "                    x_temp = self.deal_with_na_values(x_temp)\n",
        "                elif transformation_type == 'drop':\n",
        "                    x_temp = self.drop_unneeded_columns(x_temp, column_names)\n",
        "\n",
        "        return x_temp\n",
        "\n",
        "    @staticmethod\n",
        "    def deal_with_na_values(data, verbose=False):\n",
        "\n",
        "      mode_fill_columns = ['Financial Stress', 'Dietary Habits']\n",
        "      zero_fill_column = ['CGPA', 'Degree', 'Profession', 'Academic Pressure',\n",
        "                          'Study Satisfaction', 'Job Satisfaction',\n",
        "                          'Work Pressure']\n",
        "\n",
        "      for col in mode_fill_columns:\n",
        "        data[col] = data[col].fillna(data[col].mode()[0])\n",
        "\n",
        "      for col in zero_fill_column:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "      return data\n",
        "\n",
        "    @staticmethod\n",
        "    def drop_unneeded_columns(data, column_names):\n",
        "        return data.drop(columns=column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "XoXvVqRahumr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "2. EDA - This is the class that will allow us to display information about the data\n",
        "         The idea is that this information that we can extract/plot will allow us to tweak out data-preprocessing pipeline\n",
        "         to achieve better and more generalisable results\n",
        "\n",
        "         TODO:\n",
        "         Assess the overall distribution of 'Depressed' and 'not depressed' individuals in the dataset\n",
        "         Confimatory factor analysis - or another method of figuring out how we can best assess each variables affect in building up\n",
        "                                       a model which can generalise and help predict which variables affect the overall ability of the model\n",
        "         look on kaggle for methods other users have used to\n",
        "\"\"\"\n",
        "class DataAnalyser:\n",
        "  def __init__(self, dataframe=None, target=None):\n",
        "    self.df = dataframe\n",
        "    self.target = target\n",
        "\n",
        "  def view_cleaning_analysis(self, dataframe=None, target=None):\n",
        "    if dataframe is not None:\n",
        "      self.df = dataframe\n",
        "    if target is not None:\n",
        "      self.target = target\n",
        "\n",
        "    self.column_summary()\n",
        "    # self.plot_columns()\n",
        "    self.plot_column_distribution()\n",
        "\n",
        "  def view_pre_processing_analysis(self):\n",
        "    pass\n",
        "\n",
        "  def plot_column_distribution(self):\n",
        "    # TODO: Verify we have each important column covered\n",
        "    plots = {'pie_chart': [] ,\n",
        "              'bar_graph': [],\n",
        "              'box_plot': []}\n",
        "    # plots = {'pie_chart': ['Gender', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness'] ,\n",
        "    #           'bar_graph': ['Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'],\n",
        "    #           'box_plot': ['Age']}\n",
        "\n",
        "    for plot_type, columns in plots.items():\n",
        "      if plot_type == 'pie_chart':\n",
        "        self.plot_pie_chart(columns)\n",
        "      elif plot_type == 'bar_graph':\n",
        "        self.plot_bar_graph(columns)\n",
        "      elif plot_type == 'box_plot':\n",
        "        self.plot_box_plot(columns)\n",
        "\n",
        "      self.perform_t_test()\n",
        "\n",
        "  def plot_columns(self):\n",
        "    print(\"*\" * 50)\n",
        "    print(\"PLOTTING EACH COLUMN\")\n",
        "    print(\"*\" * 50)\n",
        "\n",
        "    for col in self.df.columns:\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      print(f\"Plotting: {col}\")\n",
        "\n",
        "      if pd.api.types.is_numeric_dtype(self.df[col]):\n",
        "        sns.boxplot(x=self.df[col])\n",
        "        plt.title(f'Boxplot of {col}')\n",
        "      else:\n",
        "        sns.countplot(x=self.df[col], order=self.df[col].value_counts().index[:20])  # limit to top 20 if too many\n",
        "        plt.title(f'Countplot of {col}')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      print(\"-\" * 50)\n",
        "\n",
        "  def column_summary(self):\n",
        "    print(\"*\" * 50)\n",
        "    print(\"COLUMN SUMMARY\")\n",
        "    print(\"*\" * 50)\n",
        "\n",
        "    for col in self.df.columns:\n",
        "      col_type = 'Numerical' if pd.api.types.is_numeric_dtype(self.df[col]) else 'Categorical'\n",
        "      null_count = self.df[col].isnull().sum()\n",
        "      null_percent = (null_count / len(self.df)) * 100\n",
        "\n",
        "      print(f\"Column: {col}\")\n",
        "      print(f\"Type: {col_type}\")\n",
        "      print(f\"Nulls: {null_count} ({null_percent:.2f}%)\")\n",
        "      print(\"-\" * 50)\n",
        "\n",
        "  def perform_t_test(self):\n",
        "    ...\n",
        "\n",
        "  def plot_pie_chart(self, columns):\n",
        "    for column in columns:\n",
        "      depressed_df = self.df[self.target == 1][column]\n",
        "      non_depressed_df = self.df[self.target == 0][column]\n",
        "      # code for plotting pie chart\n",
        "\n",
        "\n",
        "  def plot_bar_graph(self, columns):\n",
        "    for column in columns:\n",
        "      depressed_df = self.df[self.target == 1][column]\n",
        "      non_depressed_df = self.df[self.target == 0][column]\n",
        "      # code for plotting bar graph\n",
        "\n",
        "\n",
        "  def plot_box_plot(self, columns):\n",
        "    for column in columns:\n",
        "      depressed_df = self.df[self.target == 1][column]\n",
        "      non_depressed_df = self.df[self.target == 0][column]\n",
        "      # code for plotting box_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "cbcCgqZwhwLj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "3. Data Pre-Processing\n",
        "\n",
        "COLUMNS -\n",
        "id: Can be dropped\n",
        "Name: Can be dropped\n",
        "Gender: binary encoding\n",
        "age: Normalised\n",
        "city: Can be dropped\n",
        "Working professional or Student: Binary encoding\n",
        "Profession: Frequency-encoding\n",
        "Academic Pressure: Normalised\n",
        "Work Pressure: Normalised\n",
        "CGPA: Normalised\n",
        "Study Satisfaction: Normalised\n",
        "Job Satisfaction: Normalised\n",
        "Sleep Duration: mapped to values and normalised\n",
        "Dietary Habits: mapped to values and normalised\n",
        "Degree: Frequency encoding\n",
        "Suicidal Thoughts: Binary Encoding\n",
        "Work/Study Hours: Normalised\n",
        "Financial stress: Normalised\n",
        "Mental Illness: Binary Encoding\n",
        "Depression: Target variable (no pre-processing needed)\n",
        "\n",
        "TODO:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Basic preprocessing configuration\n",
        "preprocessing_transformations = [\n",
        "    {'binary_encode': ['Gender', 'Have you ever had suicidal thoughts ?',\n",
        "                       'Family History of Mental Illness',\n",
        "                       'Working Professional or Student']},\n",
        "    {'map_sleep_column': ['Sleep Duration']},\n",
        "    {'map_diet_column': ['Dietary Habits']},\n",
        "    {'frequency_encode': ['Profession', 'Degree']},\n",
        "    {'normalise': ['Financial Stress', 'Age', 'Academic Pressure', 'Work Pressure',\n",
        "                   'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Work/Study Hours', 'Financial Stress']}\n",
        "]\n",
        "\n",
        "\n",
        "class PreProcessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    This class will handle the Pre-Processin of our data before passing to the Model\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, transformations):\n",
        "        self.transformations = transformations\n",
        "        self.mappings = {\n",
        "            'Gender': {'Male': 0, 'Female': 1},\n",
        "            'Have you ever had suicidal thoughts ?': {'Yes': 0, 'No': 1},\n",
        "            'Family History of Mental Illness': {'Yes': 0, 'No': 1},\n",
        "            'Working Professional or Student': {'Working Professional': 0, 'Student': 1},\n",
        "        }\n",
        "        self.sleep_mapping = {\n",
        "        \"More than 8 hours\":9,\n",
        "        'Less than 5 hours':4,\n",
        "        '5-6 hours':5.5,\n",
        "        '7-8 hours':7.5,\n",
        "        '1-2 hours':1.5,\n",
        "        '6-8 hours':7,\n",
        "        '4-6 hours':5,\n",
        "        '6-7 hours':6.5,\n",
        "        '10-11 hours':10.5,\n",
        "        '8-9 hours':8.5,\n",
        "        '9-11 hours':10,\n",
        "        '2-3 hours':2.5,\n",
        "        '3-4 hours':3.5,\n",
        "        'Moderate':6,\n",
        "        '4-5 hours':4.5,\n",
        "        '9-6 hours':7.5,\n",
        "        '1-3 hours':2,\n",
        "        '1-6 hours':4,\n",
        "        '8 hours':8,\n",
        "        '10-6 hours':8,\n",
        "        'Unhealthy':3,\n",
        "        'Work_Study_Hours':6,\n",
        "        '3-6 hours':4.5,\n",
        "        '9-5':7,\n",
        "        '9-5 hours':7,\n",
        "        }\n",
        "        self.diet_mapping ={\n",
        "            'More Healty':0,\n",
        "            'Healthy':1,\n",
        "            'Less than Healthy':2,\n",
        "            'Less Healthy':2,\n",
        "            'Moderate':3,\n",
        "            'Unhealthy':4,\n",
        "            'No Healthy':4,\n",
        "        }\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "      self.data_analyser = DataAnalyser(x, y)\n",
        "      return self\n",
        "\n",
        "    def transform(self, x):\n",
        "        x_temp = x.copy()\n",
        "\n",
        "        for transformation in self.transformations:\n",
        "            for transformation_name, column_names in transformation.items():\n",
        "                if transformation_name == 'drop_columns':\n",
        "                    x_temp = self.drop_columns(x_temp, column_names)\n",
        "                elif transformation_name == 'binary_encode':\n",
        "                    x_temp = self.encode_columns(x_temp, column_names, self.mappings)\n",
        "                elif transformation_name == 'normalise':\n",
        "                    x_temp = self.normalise_columns(x_temp, column_names)\n",
        "                elif transformation_name == 'map_sleep_column':\n",
        "                    x_temp = self.map_sleep_values(x_temp, column_names, self.sleep_mapping)\n",
        "                elif transformation_name == 'frequency_encode':\n",
        "                    x_temp = self.frequency_encode(x_temp, column_names)\n",
        "                elif transformation_name == 'map_diet_column':\n",
        "                    x_temp = self.map_dietary_value(x_temp, column_names, self.diet_mapping)\n",
        "\n",
        "        # print('*'*50)\n",
        "        # self.data_analyser.view_cleaning_analysis(x_temp)\n",
        "        # print('*'*50)\n",
        "\n",
        "        return x_temp\n",
        "\n",
        "    @staticmethod\n",
        "    def drop_columns(data, column_names):\n",
        "        data.drop(columns=column_names, inplace=True)\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_columns(data, column_names, mappings):\n",
        "        for column in column_names:\n",
        "            if column in mappings:\n",
        "                data[column] = data[column].map(mappings[column])\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def map_sleep_values(data, column_names, mapping):\n",
        "        for column in column_names:\n",
        "            data[column] = data[column].map(mapping)\n",
        "            data[column] = data[column].fillna(data[column].mode()[0])\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def map_dietary_value(data, column_names, mapping):\n",
        "        for column in column_names:\n",
        "            data[column] = data[column].map(mapping)\n",
        "            data[column] = data[column].fillna(data[column].mode()[0])\n",
        "        return data\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def frequency_encode(data, column_names):\n",
        "        for column in column_names:\n",
        "            if column in data.columns:\n",
        "                freq = data[column].value_counts() / len(data)\n",
        "                data[column] = data[column].map(freq)\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def one_hot_encode(data, column_names):\n",
        "        for column in column_names:\n",
        "            if column in data.columns:\n",
        "                one_hot = pd.get_dummies(data[column], prefix=column)\n",
        "                data = pd.concat([data, one_hot], axis=1)\n",
        "                data.drop(columns=[column], inplace=True)\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def normalise_columns(data, column_names):\n",
        "        scaler = MinMaxScaler()  # Initialize MinMaxScaler\n",
        "        for column in column_names:\n",
        "            if column in data.columns:\n",
        "                # Reshape for MinMaxScaler since it expects 2D input\n",
        "                data[column] = scaler.fit_transform(data[[column]])\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "sQ-OrqqibQNg"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4. Creating Model / Training / Evaluating\n",
        "\n",
        "TODO:\n",
        "save TP, TN, FP, FN values for each iteration, save all values and average them\n",
        "\"\"\"\n",
        "\n",
        "# Define model parameters\n",
        "logistic_regression_params = {'max_iter': 1000, 'random_state': 42}\n",
        "decision_tree_params = {'criterion': 'gini', 'max_depth': 3, 'random_state': 42}\n",
        "random_forest_params = {'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
        "svm_params = {'kernel': 'linear', 'C': 1.0}\n",
        "knn_params = {'n_neighbors': 5}\n",
        "\n",
        "\n",
        "# Define models\n",
        "models = {'Logistic_regression': LogisticRegression(**logistic_regression_params),\n",
        "          'decision_tree': DecisionTreeClassifier(**decision_tree_params),\n",
        "          'random_forest': RandomForestClassifier(**random_forest_params)}\n",
        "# models.append({'SVM': SVC(**svm_params)})\n",
        "# models.append({'K-Nearest Neighbors': KNeighborsClassifier(**knn_params)})\n",
        "\n",
        "class Trainer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, models, n_splits=5):\n",
        "    self.models = models\n",
        "    self.n_splits = n_splits\n",
        "    self.results = {}\n",
        "    self.results_analyser = ResultsAnalyser()\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for model_name, model in self.models.items():\n",
        "      accuracies = []\n",
        "      tp_percentages, tn_percentages, fp_percentages, fn_percentages = [], [], [], []\n",
        "      for train_idx, val_idx in skf.split(x, y):\n",
        "        x_train, x_val = x.iloc[train_idx], x.iloc[val_idx]\n",
        "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "        model.fit(x_train, y_train)\n",
        "        y_pred = model.predict(x_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
        "\n",
        "        # Total samples in fold\n",
        "        total = len(y_val)\n",
        "\n",
        "        # Store percentages\n",
        "        tp_percentages.append(tp / total)\n",
        "        tn_percentages.append(tn / total)\n",
        "        fp_percentages.append(fp / total)\n",
        "        fn_percentages.append(fn / total)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "      self.results[model_name] = {\n",
        "        'accuracy': np.mean(accuracies),\n",
        "        'tp%': np.mean(tp_percentages),\n",
        "        'tn%': np.mean(tn_percentages),\n",
        "        'fp%': np.mean(fp_percentages),\n",
        "        'fn%': np.mean(fn_percentages)}\n",
        "    return self\n",
        "\n",
        "  def transform(self,x):\n",
        "    return x\n",
        "\n",
        "  def get_results(self):\n",
        "    self.results_analyser.view_results(self.results)\n",
        "    print(self.results)\n",
        "# results_analyser = ResultsAnalyser(model_results)\n",
        "# results_analyser.view_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "4Ihdisz3HiM4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "5. Analysing results\n",
        "'''\n",
        "\n",
        "class ResultsAnalyser:\n",
        "    def __init__(self):\n",
        "      ...\n",
        "\n",
        "    def view_results(self, results):\n",
        "        for result in results.items():\n",
        "            print(result)\n",
        "\n",
        "    def create_confusion_matrix(fp,fn,tp,tn):\n",
        "      ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI-qUZ0hHiM4",
        "outputId": "c00a41a9-a847-4319-bbd1-b514b8802b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "COLUMN SUMMARY\n",
            "**************************************************\n",
            "Column: id\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Name\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Gender\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Age\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: City\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Working Professional or Student\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Profession\n",
            "Type: Categorical\n",
            "Nulls: 36630 (26.03%)\n",
            "--------------------------------------------------\n",
            "Column: Academic Pressure\n",
            "Type: Numerical\n",
            "Nulls: 112803 (80.17%)\n",
            "--------------------------------------------------\n",
            "Column: Work Pressure\n",
            "Type: Numerical\n",
            "Nulls: 27918 (19.84%)\n",
            "--------------------------------------------------\n",
            "Column: CGPA\n",
            "Type: Numerical\n",
            "Nulls: 112802 (80.17%)\n",
            "--------------------------------------------------\n",
            "Column: Study Satisfaction\n",
            "Type: Numerical\n",
            "Nulls: 112803 (80.17%)\n",
            "--------------------------------------------------\n",
            "Column: Job Satisfaction\n",
            "Type: Numerical\n",
            "Nulls: 27910 (19.84%)\n",
            "--------------------------------------------------\n",
            "Column: Sleep Duration\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Dietary Habits\n",
            "Type: Categorical\n",
            "Nulls: 4 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Degree\n",
            "Type: Categorical\n",
            "Nulls: 2 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Have you ever had suicidal thoughts ?\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Work/Study Hours\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Financial Stress\n",
            "Type: Numerical\n",
            "Nulls: 4 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Family History of Mental Illness\n",
            "Type: Categorical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "**************************************************\n",
            "COLUMN SUMMARY\n",
            "**************************************************\n",
            "Column: Gender\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Age\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Working Professional or Student\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Profession\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Academic Pressure\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Work Pressure\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: CGPA\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Study Satisfaction\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Job Satisfaction\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Sleep Duration\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Dietary Habits\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Degree\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Have you ever had suicidal thoughts ?\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Work/Study Hours\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Financial Stress\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "Column: Family History of Mental Illness\n",
            "Type: Numerical\n",
            "Nulls: 0 (0.00%)\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "('Logistic_regression', {'accuracy': np.float64(0.9376616915422886), 'tp%': np.float64(0.14626154939587777), 'tn%': np.float64(0.7914001421464107), 'fp%': np.float64(0.026886993603411513), 'fn%': np.float64(0.03545131485429993)})\n",
            "('decision_tree', {'accuracy': np.float64(0.9100995024875622), 'tp%': np.float64(0.15526652452025586), 'tn%': np.float64(0.7548329779673064), 'fp%': np.float64(0.063454157782516), 'fn%': np.float64(0.02644633972992182)})\n",
            "('random_forest', {'accuracy': np.float64(0.9275479744136461), 'tp%': np.float64(0.13549395877754086), 'tn%': np.float64(0.7920540156361052), 'fp%': np.float64(0.026233120113717128), 'fn%': np.float64(0.04621890547263681)})\n",
            "{'Logistic_regression': {'accuracy': np.float64(0.9376616915422886), 'tp%': np.float64(0.14626154939587777), 'tn%': np.float64(0.7914001421464107), 'fp%': np.float64(0.026886993603411513), 'fn%': np.float64(0.03545131485429993)}, 'decision_tree': {'accuracy': np.float64(0.9100995024875622), 'tp%': np.float64(0.15526652452025586), 'tn%': np.float64(0.7548329779673064), 'fp%': np.float64(0.063454157782516), 'fn%': np.float64(0.02644633972992182)}, 'random_forest': {'accuracy': np.float64(0.9275479744136461), 'tp%': np.float64(0.13549395877754086), 'tn%': np.float64(0.7920540156361052), 'fp%': np.float64(0.026233120113717128), 'fn%': np.float64(0.04621890547263681)}}\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "dataset = pd.read_csv('train.csv')\n",
        "\n",
        "# Removing target Column\n",
        "target = dataset.pop('Depression')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('cleaning', Cleaner(cleaning_transformations)),\n",
        "    ('preprocessor', PreProcessor(preprocessing_transformations)),\n",
        "    ('training', Trainer(models))\n",
        "])\n",
        "\n",
        "pipeline.fit(dataset, target)\n",
        "\n",
        "model_results = pipeline.named_steps['training'].get_results()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}